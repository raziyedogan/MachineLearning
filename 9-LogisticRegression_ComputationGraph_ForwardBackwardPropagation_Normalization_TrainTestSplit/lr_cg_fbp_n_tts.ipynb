{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d8006a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ed3aa",
   "metadata": {},
   "source": [
    "Logistic regression, bir classification algoritmasıdır.\n",
    "\n",
    "Logistic regresison genelde 0 ve 1 sonucu verir. Bu durum binary classification'dır. Mesela kedi ve köpek olmak üzere iki sınıf olması durumunda bu binary classification'dur. Kedi ve Köpek sınıflarını 0 ve 1 şeklinde temsil edebiliriz.\n",
    "\n",
    "Birde şunu belirtmek gerek ki, veri setindeki veriler birer resim ise bu resimler piksellerden oluşur ve logistic regression modeline resmi öğretebilmek için her bir resimdeki piksel değerlerini bir numpy array'e depolarız. Yani data'yı bir numpy array'e çevirmeliyiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883e740",
   "metadata": {},
   "source": [
    "### Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738df3e",
   "metadata": {},
   "source": [
    "Computation Graph, matematiksel ifadeleri görselleştirmek için kullandığımız bir yöntemdir.\n",
    "\n",
    "c = √ a^2 + b^2  \n",
    "\n",
    "Bu matematiksel ifadenin computation graph ile görselleştirilmiş hali şu şekildedir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6124270f",
   "metadata": {},
   "source": [
    "<img src=\"computation_graph.png\" style=\"width:700px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccaa129",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "Şimdi de logistic regression'un computation graph'ına bakalım."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ce8b0",
   "metadata": {},
   "source": [
    "<img src=\"log_computation.png\" style=\"width:900px;height:500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c825d1",
   "metadata": {},
   "source": [
    "Bir resmi train ettiğimizi düşünelim. Train etmek, resmi modele uyduracağımız anlamına gelir. \n",
    "\n",
    "Mavi yuvarlaklar resimdeki her bir pikseli ifade eder. Pikseller, eğer resim bgr ise renk tonlarına göre 0 ile 255 arasında, gri ise renk tonlarına göre 0 ile 1 arasında sayısal değerlerdir. Toplamda 4096 tane piksel bulunmakta. Bu pikselleri, veri setindeki feature'ler yani sütunlar olarak düşünebiliriz.\n",
    "\n",
    "Her bir pikseli bir ağırlık ile çarpıyoruz. Elde edilen her bir değer toplanır. Sonrasında toplam değerine bir bias değeri eklenir. Bu işlemler sonucunda elde edilen değere şekil üzerinde z denmiştir.\n",
    "\n",
    "z = b + px1w1 + px2w2 + ... + px4096*w4096\n",
    "\n",
    "Sonrasında z değerine sigmoid function uygulanıyor. \n",
    "\n",
    "Sigmoid function, değeri 0 ile 1 arasında bir değere çeker.\n",
    "\n",
    "z değerine sigmoid function uygulanması ile tahmin edilen y_head değeri elde edilir ve y_head değeri 0 ile 1 arasında probabilistic değerdir.\n",
    "\n",
    "Mesela tüm bu işlemlerin ardından 0.9 değerini elde edelim. Threshold değeri 0.5 tir ve 0.5'in üzerindeki değerler 1, 0.5'in altındaki değerler 0 olsun diyoruz. 0.9 değeri 0.5 değerinden büyük olduğuna göre sonuç olarak 1 çıktısı elde edilir. Yani resim üzerindeki işaret 1'dir tahmini sağlanmıştır.\n",
    "\n",
    "Ayrıca weight ve bias değerleri güncellenmelidir çünkü burada bir resim için eğitim yapılmıştır ve veri setindeki geri kalan her bir resmin eğitimi için w ve b değerleri güncellenmelidir. Bu güncelleme işlemi sigmoid fonksiyonunun türevinin alınması ile yapılır.\n",
    "\n",
    "Modelde öğrenilen şeyler weight ve bias değerleridir.\n",
    "\n",
    "Mesela başlangıçta tüm w değerleri 0 ve b değeride 0 olsun. Bu durumda z=0 elde ederiz. 0<0.5 olduğuna göre 0 sonucu elde edilir ama resimdeki işaret 1'dir. Dolayısıyla yanlış tahmin yapılmıştır. Bu durumda geriye doğru gidilir. Sigmoid fonksiyonunun türevi alınır ve türevini alarak bias ile weight değerlerini güncelliyoruz. Sonra diğer resim alınır ve piksel değerleri güncellenmiş weight değerleri ile çapılırarak tüm sonuçlar toplanır ve güncellenmiş bias değeri bu toplamm sonucu ile toplanır sonra bu sonuca sigmoid fonksiyonu uygulanır ve son sonuç elde edilir. Mesela bu sefer de tahmin doğru olsun. Sonrasında tekrar güncelleme işlemleri yapılmalıdır. Tekrar sigmoid fonksiyonunun türevi alınır, sigmoid fonksiyonun geri kalan kısmında gördüğünüz lineer işlemlerin türevi alınır ve weight ve bias güncellenir.\n",
    "\n",
    "Böylece weight ve bias değerlerini sürekli güncelleyerek tüm resimler eğitilir. En sonunda elde edilen weight ve bias değerleri, tüm resimlere göre eğitilmiş olan logistic regression modelinin katsayıları ve bias değeri oluyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f784822",
   "metadata": {},
   "source": [
    "### Initializing Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba48643",
   "metadata": {},
   "source": [
    "Weight ve bias parametrelerdir. Bu parametrelerin ilk değerlerini seçebilmek için bazı teknikler vardır. Bu teknikleir Deep Learning bölümünde öğreneceğiz. Şimdilik genelde literatürde bu değerlerin kullanılmasından dolayı weight için başlangıç değerini 0.01 olarak ve bias değerini 0 olarak seçelim.\n",
    "\n",
    "Weight değerini 0 değilde 0.01 seçme sebebimiz, eğer 0 seçseydik weight'ler ve bias öğrenemezdi. Yani sonuca ulaştıktan sonra weight ve bias değerlerinin güncellenmesi için geriye dönüldüğünde weight değerleri 0 olduğunda güncellenecek bir şey olmadığından güncelleme gerçekleşemez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffd978",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c858bb1",
   "metadata": {},
   "source": [
    "Pikseller ile cost function arasındaki işlemlerin toplamına Forward Propagation denir. İleriye doğru gitmek şeklinde düşünebiliriz.\n",
    "\n",
    "z değeri, resmin piksellerinin ağırlıkları ile çarpımı sonucunda tüm değerlerin toplanıp, bu toplam değeri ile de bias değerinin toplanması sonucunda elde edilir. Sonrasında forward propagation devam ediyor ve z değeri sigmoid function içerisine koyularak 0 ile 1 arasında bir değer elde edilir ve sonrasında y_head (probability) değeri elde edilir. \n",
    "\n",
    "Sonrasında loss(error) function hesaplanır.\n",
    "\n",
    "<font color=\"LightSeaGreen\"><br>\n",
    "LOSS FUNCTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aaea10",
   "metadata": {},
   "source": [
    "<img src=\"loss.jpg\" style=\"width:400px;height:90px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ddd00a",
   "metadata": {},
   "source": [
    "Loss function matematiksel formülü yukarıda gördüğünüz gibidir.\n",
    "\n",
    "Gerçek değer ile tahmin edilen değer aynı ise loss değeri 0'dır. Gerçek değer ile tahmin edilen değer farklı ise oldukça büyük bir loss değeri elde edilir. \n",
    "\n",
    "Loss = hata = kayıp  ➡️  Bunlar aynı ifadelerdir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe0c08",
   "metadata": {},
   "source": [
    "<font color=\"SandyBrown\"><br>\n",
    "COST FUNCTION: Her bir resim için bir loss function değeri vardır ve bu loss function değerlerinin hepsinin toplamı cost function değeridir. Yani tüm hataların toplamı cost function değeridir. Eğer cost function değeri yüksek ise modelin iyi olduğu söylenemez. Bu durumda weight değerleri yanlıştır ve bu değerlerin güncellenmesi gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b71b2c",
   "metadata": {},
   "source": [
    "Logistic regression'un computation graph'ında bir resim için forward propagation tamamen gerçekleştirilsin. Yani baştan sona işlemler yapılsın. Sonrasında loss fonksiyonuna elde ettiğimiz y_head değerini (tahmin edilen değer) ve y değerini (ilk baştaki gerçek değer) vererek, loss function değerini elde ederiz.\n",
    "\n",
    "Bu bir resim için yapılmıştır. Sonrasında aynı şekilde ikinci resim için de loss function değeri elde ederiz ve böylece ikinci resim için de forward propagation'u tamamlamış oluruz. Diğer resimlere de forward propagation yapmalıyız. \n",
    "\n",
    "Tüm resimler için forward propagation'u nasıl yapabiliriz? :\n",
    "\n",
    "Her bir resmi for döngüsü içerisine alarak yapabiliriz fakat for döngüsü çok zaman aldığı için çalışma zamanı açısından kullanışlı bir yöntem değildir.\n",
    "\n",
    "Bir diğer yöntem ise, bir numpy array'in satırları pikselleri, sütunları resimleri ifade edecek şekilde ayarlarız. Yani bir matrisi bir kerede forward propagation yaparak her bir resim için bir loss değeri elde ederiz. Sonra tüm bu elde edilen loss değerlerini toplayarak bir tane cost değeri elde ederiz. Eğer cost değeri yüksek ise modelin doğru olmadığını anlarız. Bu durumda weight değerlerini ve bias değerini cost function'a göre güncelleriz.\n",
    "\n",
    "Amaç weight değerlerini ve bias değerini güncelleyerek cost function değerini azaltmaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670de8c",
   "metadata": {},
   "source": [
    "Weight değerlerini ve bias değerini güncelleme işlemine Backward Propagation denir. Yani en sondan en başa doğru gitmeye Backward Propagation denir.\n",
    "\n",
    "Gradient Descent algoritmasını kullanarak weight ve bias değerlerini optimize edeceğiz. Yani weight ve bias için cost'a göre en uygun değerleri bulacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20caf6a7",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619b062",
   "metadata": {},
   "source": [
    "Başlangıçta weight ve bias 'a atadığımız değerlerin yanlışlığı sonucunda yüksek bir cost değeri elde ederiz. Bu durumda weight ve bias değerlerini, cost fonksiyonunu azaltacak şekilde güncellemeliyiz. Backward Propagation süreci, cost funciton'dan başlayarak geriye doğru gidilmesi ve weight ve bias değerlerinin güncellenmesidir.\n",
    "\n",
    "Backward Propagation yaparken kullanılan metod Gradient Descent'tir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29420b",
   "metadata": {},
   "source": [
    "### Optimization Algorithm with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b687a",
   "metadata": {},
   "source": [
    "Cost function değerinin en az olmasını sağlsayan weight ve bias değerlerini bulmalıyız. Yani cost function değerini en az yapacak optimize parametreleri bulmalıyız.\n",
    "\n",
    "Eğer hataların toplamı çok ise bu yanlış tahmin yapıldığı anlamına gelir. Çünkü hata fonksiyonunu doğru ya da yanlış yaptığımız tahminler oluşturur. Eğer yanlış tahmin yapılmış ise hata değeri yüksek, doğru tahmin yapılmış ise hata değeri düşüktür.\n",
    "\n",
    "Cost değeri weight ve bias parametrelerinin değerlerine bağlıdır. Dolayısıyla cost değerini azaltmak için weight ve bias değerlerinin güncellenmesi gereklidir.\n",
    "\n",
    "Model, weight ve bias parametlerini öğrenmeli ve sonucunda bu parametreler cost'u azaltır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afb09d",
   "metadata": {},
   "source": [
    "<img src=\"gradient.png\" style=\"width:800px;height:500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b055ff",
   "metadata": {},
   "source": [
    "Yukarıdaki grafiği inceleyelim. bias=0 olarak düşünün. x ekseni weight, y ekseni cost değerini ifade etmekte. Cost fonksiyonunun minimum değeri her zaman 0 olamaz. Ama minimum bir değeri vardır.\n",
    "\n",
    "Weight değeri 5 iken cost değeri 1.5'tir. Eğer weight değerleri 5 ise forward propagation yaptıktan sonra cost fonskiyonunun değeri 1.5 oluyormuş. Görselde gördüğümüz gibi weight değerini azaltırsak, min cost'a doğru ilerlemiş oluruz.\n",
    "\n",
    "w := w - step ifadesinin anlamı, w değerlerini güncelle demektir. Weight değerinden step'i çıkararız ve elde edilen yeni değer güncel w değeridir.\n",
    "\n",
    "Step: weight değeri 5 ve cost değeri 1.5 olan kırmızı çizgi üzerindeki siyah noktanın kestiği line, bu noktanın bu fonksiyona göre eğimidir. Bu eğim step'tir. \n",
    "\n",
    "slope1 değeri mesela 3 olsun ve weight değerinin güncellenmesi sonucunda yeni weight değeri 5-3=2 olur. Cost değeri bir önceki adımdaki değere göre daha küçük ama henüz minimum noktada değil. Dolayısıyla bir kere daha forward propagation yapalım. \n",
    "\n",
    "Bu sefer cost değeri 0.4 oldu. Fakat yine cost değeri minimum değil. Dolayısıyla bir step daha ilerleriz.\n",
    "\n",
    "slop22 = 0.7 'dir. 2-0.7=1.3 (w-slope2) elde edilir. Yani yeni weight değerleri 1.3'tür. Ve cost değeri 0.3'tür. Minimum cost değeri budur fakat bu değerin minimum olup olmadığı algoritma tarafından bilinmiyor. Şekilde görebiliyoruz ama gerçekte minimum olup olmadığını bilemeyiz. Dolayısıyla bir kere daha türev alırız.\n",
    "\n",
    "Slope3=0.01 'dir. 1.3-0.01=1.29  (w-slope3) elde edilir. 1.29 değeri neredeyse 1.3 (w) 'e eşittir. Yani slope3 neredeyse 0 yani burada neredeyse değişim yoktur.\n",
    "\n",
    "<font color = \"DodgerBlue\"><br>\n",
    "Değişim yok ise minimum noktaya ulaşılmış demektir.\n",
    "    \n",
    "En son güncellemede weigth değeri değişmedi. Dolayısıyla cost fonksiyonunun minimum noktasını bulmuş olduk.\n",
    "    \n",
    "Bir grafiğin bir noktaya göre türevini alırsak, o grafiğin o noktaya göre eğimini bulmuş oluruz.\n",
    "    \n",
    "Yani burada cost fonksiyonunun weight'e göre eğimini bulduk. Eğer cost için minimum değerdeysek, eğim (slope) 0 'dır.\n",
    "\n",
    "<font color = \"LimeGreen\"><br>    \n",
    "Bir fonksiyonun bir noktaya göre türevi, o fonksiyonun eğimini verir. Yani minimum cost değerini bulabilmek için o fonksiyonun o noktaya göre türevini sıfıra eşitlemeliyiz. Artık weight değeri değişmiyor ise minimum cost değerine ulaşılmış demektir.\n",
    "    \n",
    "Tüm bu işlemler bias içinde aynıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ed612",
   "metadata": {},
   "source": [
    "<img src=\"cost.png\" style=\"width:400px;height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d9c007",
   "metadata": {},
   "source": [
    "Yukarıdaki formülü açıklayalım. Burada J cost fonksiyonudur. b=0 olduğundan burada cost fonksiyonunun weight'e (w) göre türevinin alınması söyleniyor. Yani aslında bu formül w := w - step ifadesi ile aynıdır.\n",
    "\n",
    "Formülde α işareti, learning rate 'dir. Learning rate, öğrenme hızı, öğrenme oranı olarak nitelendirilir.\n",
    "\n",
    "Mesela Paris'teyiz ve Madrid'e gitmek istiyoruz. Bizim hızımız (learning rate) küçüktür. Bu durumda Madrid'e çok yavaş gideriz ve çok uzun zaman alır. Eğer hızımız (learning rate) çok yüksek ise de hiçbir zaman Madrid'e gidemeyebiliriz çünkü kaza yapabiliriz. Bu yüzde hız için (learning rate) en uygun değeri seçmeliyiz.\n",
    "\n",
    "w ve b güncellenebilen parametrelerdir. α ise hyperparameter'dir. Yani önce α değerini seçeriz ve sonrasında bu değeri değiştirerek ayarlarız.\n",
    "\n",
    "<font color = \"Orange\"><br>  \n",
    "Learning rate değeri çok büyük olmamalı ve çok küçük de olmamalıdır. Learning rate değerini seçmek için denemek zorundayız.\n",
    "    \n",
    "Genelde başlangıçta learning rate değeri 0.01 seçilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662a927",
   "metadata": {},
   "source": [
    "Backward propagation ile geri giderken weight ve bias değerlerini, cost fonksiyonun weight ve bias'a göre türevini alarak güncelleriz. Türevi almak eğimi bulmak demektir. Eğer eğim yüksek ise min cost değerinden uzağız demektir, eğer eğim 0 ise min cost değerindeyiz demektir.\n",
    "\n",
    "Weight ve bias değerlerini yukarıdaki formüle göre güncelleriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e36ae",
   "metadata": {},
   "source": [
    "<img src=\"cost_grafik.png\" style=\"width:700px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6045193",
   "metadata": {},
   "source": [
    "Cost değerinin değişimlerini grafikte görmekteyiz. Cost değeri başlangıçta 14 çıkmış ve sonrasında giderek 0'a yaklaşmış.\n",
    "\n",
    "Yani backward ve forward'lar arttıkça cost değeri giderek 0'a yaklaşmıştır.\n",
    "\n",
    "Grafikte gördüğünüz üzere cost değeri 0'a çok yaklaşmış ve artık azalmamaya başlamış dolayısıyla bu noktada durdurulmuştur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ff2c2",
   "metadata": {},
   "source": [
    "Şimdi de logistic regression algoritmasını uygulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdcf59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c06104",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b1da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b4dfac",
   "metadata": {},
   "source": [
    "Kullanacağımız veri seti, bir tümörün iyi huylu mu, kötü huylu mu olduğunu göstermektedir.\n",
    "\n",
    "diagnosis sütununda yer alan M değerleri kötü huylu tümörü, B değerleri de iyi huylu tümörü ifade etmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b98d2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa2beb7",
   "metadata": {},
   "source": [
    "569 tane sample bulunmaktadır. Bu sample'ler DataFrame içerisinde bulunuyor. diagnosis sütunu class'tır ve iyi huylu, kötü huylu tümör şeklinde iki kategoriye sahiptir.\n",
    "\n",
    "Veri setini eğitirken, logistic regression modelini oluştururken bazı feature'leri kullanmayacağız. Mesela Unnamed: 32 isimli feature nan değerlerden oluşmakta dolayısıyla bu feature'yi kullanmayız. id isimli sütunu da kullanmayız çünkü bu sütunlar veri setini sınıflandırma konusunda bir etkiye sahip değillerdir. Tümörün yarıçapı ya da dokusu gibi özellikleri olmadığı için bu sütunları drop ederiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74b530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Unnamed: 32\",\"id\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6b4aa",
   "metadata": {},
   "source": [
    "Yukarıdaki kod ile \"Unnamed: 32\",\"id\" sütunlarını veri setinden çıkarıyoruz. \n",
    "\n",
    "axis=1 parametresi ile tüm bir sütunun drop edilmesini sağlıyoruz. axis=0 olsaydı satırın drop edilmesi sağlanırdı. \n",
    "\n",
    "inplace=True parametresi ile kaldırma işleminin kalıcı olması sağlanmıştır. Yani data değişkeninde tutulan veri setinin içerisinden data.drop \"Unnamed: 32\" ve \"id\" sütunları kalıcı olarak çıkarılmıştır.\n",
    "\n",
    "Artık veri setinde class'ımız olan diagnosis feature'si ve tümörü ayırt etmek için kullanacağımız sayısal feature'ler bulunmaktadır.\n",
    "\n",
    "Şimdi diagnosis sütunundaki M ve B değerlerini 0 ve 1 şeklinde int değerlere dönüştürelim. Çünkü sınıflandırma işleminde bu feature'yi kullanabilmemiz için string tipinde değil, categorical ya da int tipinde değerlere sahip olmalı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed484f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.diagnosis = [1 if each==\"M\" else 0 for each in data.diagnosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09dbd6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f94e6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    int64  \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33383f5",
   "metadata": {},
   "source": [
    "Böylece diagnosis feature'si artık int tipindedir.\n",
    "\n",
    "İki tane class'a sahibiz. Birinci class iyi huylu tümör, ikinci class kötü huylu tömürdür.\n",
    "\n",
    "diagnosis feataure'sinde bulunan 1 değerleri tümörün kötü huylu olduğunu, 0 değerleri tümörün iyi huylu olduğunu ifade etmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed797de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.diagnosis.values\n",
    "x_data = data.drop([\"diagnosis\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184efa96",
   "metadata": {},
   "source": [
    ".values ile numpy array'e çevirme işlemi yapılır.\n",
    "\n",
    "diagnosis feature'si çıktı değerimiz olucak. Dolayısıyla y isimli değişkene atadık.\n",
    "\n",
    "diagnosis dışındaki tüm feature'ler x ekseni olucak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b7e4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data[\"area_mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc760c8c",
   "metadata": {},
   "source": [
    "Mesela area_mean sütununun maksimum değeri 2501 'dir. Eğer area_mean feature'sini normalize etmezsek, bu feature diğer feature'lere üstünlük sağlayabilir. Mesela smoothness_se featuresindeki değerler 0.008166 gibi çok küçük değerler. Dolayısıyla area_mean feature'si smoothness_se feature'sinin ihmal edilmesine sebep olabilir. smoothness_se feature'sinin özelliğini kaybetmesine sebep olabilir. Dolayısıyla tüm feature'leri normalize etmeliyiz.\n",
    "\n",
    "Normalize işlemi, değerleri 0 ile 1 arasında ölçeklendirmek demektir.\n",
    "\n",
    "Tüm feature'lerin değerlerini 0 ile 1 aralığına çekerek feature'ler arasında modeli bozan farkların kaldırılmasını sağlamış olucaz.\n",
    "\n",
    "<font color=\"SlateBlue\"><br>\n",
    "Normalization : (x - min(x)) / (max(x) - min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe63614",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x_data - np.min(x_data))/(np.max(x_data) - np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05aef8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                  0.605518  ...      0.620776       0.141525   \n",
       "1                  0.141323  ...      0.606901       0.303571   \n",
       "2                  0.211247  ...      0.556386       0.360075   \n",
       "3                  1.000000  ...      0.248310       0.385928   \n",
       "4                  0.186816  ...      0.519744       0.123934   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                0.132056  ...      0.623266       0.383262   \n",
       "565                0.113100  ...      0.560655       0.699094   \n",
       "566                0.137321  ...      0.393099       0.589019   \n",
       "567                0.425442  ...      0.633582       0.730277   \n",
       "568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           0.668310    0.450698          0.601136           0.619292   \n",
       "1           0.539818    0.435214          0.347553           0.154563   \n",
       "2           0.508442    0.374508          0.483590           0.385375   \n",
       "3           0.241347    0.094008          0.915472           0.814012   \n",
       "4           0.506948    0.341575          0.437364           0.172415   \n",
       "..               ...         ...               ...                ...   \n",
       "564         0.576174    0.452664          0.461137           0.178527   \n",
       "565         0.520892    0.379915          0.300007           0.159997   \n",
       "566         0.379949    0.230731          0.282177           0.273705   \n",
       "567         0.668310    0.402035          0.619626           0.815758   \n",
       "568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.568610              0.912027        0.598462   \n",
       "1           0.192971              0.639175        0.233590   \n",
       "2           0.359744              0.835052        0.403706   \n",
       "3           0.548642              0.884880        1.000000   \n",
       "4           0.319489              0.558419        0.157500   \n",
       "..               ...                   ...             ...   \n",
       "564         0.328035              0.761512        0.097575   \n",
       "565         0.256789              0.559450        0.198502   \n",
       "566         0.271805              0.487285        0.128721   \n",
       "567         0.749760              0.910653        0.497142   \n",
       "568         0.000000              0.000000        0.257441   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                   0.418864  \n",
       "1                   0.222878  \n",
       "2                   0.213433  \n",
       "3                   0.773711  \n",
       "4                   0.142595  \n",
       "..                       ...  \n",
       "564                 0.105667  \n",
       "565                 0.074315  \n",
       "566                 0.151909  \n",
       "567                 0.452315  \n",
       "568                 0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96854689",
   "metadata": {},
   "source": [
    "Görüldüğü üzere tüm değerler 0 ile 1 aralığına çekilmiştir.\n",
    "\n",
    "Böylelikle normalize işlemi ile feature'lerin birbirine üstünlük sağlamaları engellenmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf94c7",
   "metadata": {},
   "source": [
    "Veri setini logistic regression algoritması ile eğiteceğiz. Ve sonucunda matematiksel bir denklem elde edilir. Bu denkleme de model denir. Bu model ile tümörün iyi huylu mu kötü huylu mu olduğu tahmin edilecek. Bu modeli test edeceğimiz data olmalı. Data içerisinde 529 tane sample var. Bu data'nın %80'ini train seti yapalım yani modeli eğiteceğimiz veri seti olsun. Veri setinin geri kalan %20'si ile de modeli test edelim. Dolayısıyla elimizdeki veri setini %80'i train, %20'side test seti olacak şekilde bölüyoruz.\n",
    "\n",
    "Veri setinin %80'lik kısmı ile eğitim gerçekleştirip modeli elde edeceğiz. Veri setinin %20'lik kısmını modele vererek iyi huylu tümör veya kötü huylu tümör şeklinde sonuçlar elde edeceğiz. Sonrasında bu sonuçların doğru olup olmadığını gerçek değerler ile kıyaslayarak anlayabiliriz. Dolayısıyla oluşturduğumuz modelin güvenilirliğini, doğruluğunu test data'sı ile anlayabiliriz.\n",
    "\n",
    "Şimdi veri setini train ve test şeklinde ayıran kodu yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab55e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0fe3d",
   "metadata": {},
   "source": [
    "y class'ın label değerleridir. x ise class'ın feature'leridir. train_test_split metoduna x ve y'yi veriyoruz ve test_size=0.2 parametresi ile x ve y'nin %20'sinin test, %80'inin train seti olması sağlanır.\n",
    "\n",
    "x'in %80'i x_train ve x'in %20'si x_test olur. y'nin %80'i y_train ve y'nin %20'si y_test olur. \n",
    "\n",
    "Her çalıştırmada train ve test setlerine verilerin dağılımlarının farklı olmaması için random_state=42 parametresi kullanılmıştır. test ve train setlerine veriler bölünürken rastgele seçilerek dağıtıldığı için kodu her çalıştırmamızda farklı doğruluk değeri elde edebiliriz. Bunu önlemek içinde random_state parametresini kullanırız. Bu parametre sayesinde kodu her çalıştırmamızda train ve test içeriği bir önceki çalıştırmamızdaki içerikleri ile aynı olur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74545c15",
   "metadata": {},
   "source": [
    "Şimdi veri setinde satır ve sütunların yerlerini değiştirelim. Logistic regression'u anlatırken bu şekilde anlattığımız için bu işlemi yapıyoruz. Ayrıyeten bir amaç yoktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b5e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (30, 455)\n",
      "x_test:  (30, 114)\n",
      "y_train:  (455,)\n",
      "y_test:  (114,)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_test: \",x_test.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62921b06",
   "metadata": {},
   "source": [
    "### Implementing Initializing Parameters and Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312fe53",
   "metadata": {},
   "source": [
    "30 tane feature bulunmaktadır. Bu feature'leri weight değerleri ile çarpıyoruz ve her bir sonucu topluyoruz. Sonra da bu toplam sonucu ile bias değerini topluyoruz. weight ve bias 'ın başlangıç değerlerini rastgele belirliyorduk. Bu anlatılanların kodunu yazalım.\n",
    "\n",
    "Ayrıca w değeri 0 olursa, öğrenme gerçekleşemez. Genellikle weight'in başlangıç değeri 0.01 olarak seçilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b324872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b=0.0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fcb27",
   "metadata": {},
   "source": [
    "30 tane feature değeri olduğuna göre 30 tane weight değeri olmalıdır. Dolayısıyla dimesion=30 olur.\n",
    "\n",
    "w = np.full((dimension,1),0.01)\n",
    "\n",
    "Bu satır ile, satır sayısı dimension kadar yani 30 tane ve sütun sayısı 1 olan 0.01 değerlerinden oluşan bir matris oluşturdum.\n",
    "\n",
    "<font color=\"SeaGreen\"><br>\n",
    "Sigmoid function: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2bf57",
   "metadata": {},
   "source": [
    "<img src=\"sigmoid.png\" style=\"width:400px;height:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec072d",
   "metadata": {},
   "source": [
    "Yukarıda gördüğünüz sigmoid function formülüdür. Burada x değeri, z değeridir. Hatırlarsanız z değerini, feature'leri weight değerleri ile çarpıyoruz ve her bir sonucu topluyoruz ve sonra da bu toplam sonucu ile bias değerini toplayarak elde ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8cd2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94db71",
   "metadata": {},
   "source": [
    "np.exp(-z) metodu e^(-z) ifadesini sağlar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78442e2",
   "metadata": {},
   "source": [
    "### Implementing Forward and Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db484902",
   "metadata": {},
   "source": [
    "<font color=\"LimeGreen\">\n",
    "Forward and Backward Propagation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3dc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008a5af",
   "metadata": {},
   "source": [
    "Hatırlatma: Matris çarpımı kuralı, ilk matrisin sütun boyutu ile ikinci matrisin satır boyutu aynı olmalıdır.\n",
    "\n",
    "derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  \n",
    "\n",
    "Bu satırda weight'in türevi alınarak değeri güncellenmiştir. \n",
    "\n",
    "derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]\n",
    "\n",
    "Bu satırda bias'in türevi alınarak değeri güncellenmiştir. \n",
    "\n",
    "backward propagation ile weight ve bias değerleri güncellenerek minimum cost değerine ulaşmak amaçlanmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8082b",
   "metadata": {},
   "source": [
    "Yukarıda weight ve bias değerlerini ne kadar güncelleyeceğimizi return ettirdik. Şimdi de weight ve bias'ı güncelleyelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "016c5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    # updating(learning) parameters is number_of_iterarion times\n",
    "    for i in range(number_of_iterarion):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685f21d",
   "metadata": {},
   "source": [
    "Weight ve bias'ı güncellemek aslında modeli train etmektir yani eğitmektir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38d673",
   "metadata": {},
   "source": [
    "### Implementing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b713d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d589fc",
   "metadata": {},
   "source": [
    "Label'ı olmayan yani iyi huylu mu kötü huylu mu tümör olduğunu bilmediğimiz sample'ler için tahminler gerçekleştirilmiştir.\n",
    "\n",
    "Y_prediction değişkeninde yapılan tahminler tutulmaktadır. Şimdi bu tahminlerin doğruluğunu anlayabileceğimiz kodu yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c723122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692977\n",
      "Cost after iteration 10: 0.499667\n",
      "Cost after iteration 20: 0.406616\n",
      "Cost after iteration 30: 0.351936\n",
      "Cost after iteration 40: 0.315762\n",
      "Cost after iteration 50: 0.289862\n",
      "Cost after iteration 60: 0.270257\n",
      "Cost after iteration 70: 0.254795\n",
      "Cost after iteration 80: 0.242214\n",
      "Cost after iteration 90: 0.231722\n",
      "Cost after iteration 100: 0.222796\n",
      "Cost after iteration 110: 0.215080\n",
      "Cost after iteration 120: 0.208317\n",
      "Cost after iteration 130: 0.202324\n",
      "Cost after iteration 140: 0.196961\n",
      "Cost after iteration 150: 0.192121\n",
      "Cost after iteration 160: 0.187722\n",
      "Cost after iteration 170: 0.183698\n",
      "Cost after iteration 180: 0.179997\n",
      "Cost after iteration 190: 0.176577\n",
      "Cost after iteration 200: 0.173402\n",
      "Cost after iteration 210: 0.170443\n",
      "Cost after iteration 220: 0.167676\n",
      "Cost after iteration 230: 0.165080\n",
      "Cost after iteration 240: 0.162638\n",
      "Cost after iteration 250: 0.160334\n",
      "Cost after iteration 260: 0.158155\n",
      "Cost after iteration 270: 0.156091\n",
      "Cost after iteration 280: 0.154131\n",
      "Cost after iteration 290: 0.152266\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 96.49122807017544 %\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 30\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "\n",
    "    # Print test Errors\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5789a35",
   "metadata": {},
   "source": [
    "learning rate, num_iterations parametreleri hyperparameter'dir. Bu parametrelere farklı değerler vererek, modele göre uygun değeri seçeriz. Bu parametreler için farklı değerleri bir for döngüsü ile deneyerek, en yüksek accuracy değerini veren parametre değerlerini bulabiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeeaee6",
   "metadata": {},
   "source": [
    "Sklearn ile logistic regression'u bir kaç satırda yazabilmemiz mümkün."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a718a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train.T,y_train.T)\n",
    "\n",
    "print(\"test accuracy {}\".format(lr.score(x_test.T,y_test.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46970bae",
   "metadata": {},
   "source": [
    "score() metodu ile tahmin gerçekleştirilip sonrasında accuracy değeri yani tahminlerinin ne kadarının doğru olduğuna dair oran elde edilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f40e0",
   "metadata": {},
   "source": [
    "<font color=\"GoldenRod\"><br>\n",
    "Logistic regression'u iki tane seçeneğe sahip class olması durumunda kullanabiliriz. Yani binary bir output'a sahip olmalıdır."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
